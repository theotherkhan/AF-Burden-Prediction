{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "#### Hasan Khan | CS3033 083\n",
    "\n",
    "This notebook runs a 1D CNN on ECG signlas from [The 4th China Physiological Signal Challenge 2021](https://physionet.org/content/cpsc2021/1.0.0/) to predict AF Burden values for each signal. A python script equivalent of this notebook is available in the pipeline.py file. See the pdf in the Writeup folder for more information on this project.\n",
    "\n",
    "To run this notebook, install the necessary requirements from the requirements.txt file, and download the data from the link above. Modify the DATA_PATH variable to poin to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import wfdb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/Hasan/Desktop/Workspace/cpsc2021-AFIB/Project/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_record(sample_path):\n",
    "    \n",
    "    '''  returns signal, global label, local labels ''' \n",
    "    \n",
    "    sig, fields = wfdb.rdsamp(sample_path)\n",
    "    ann_ref = wfdb.rdann(sample_path, 'atr')\n",
    "    \n",
    "    label = fields['comments'][0]\n",
    "    fs = fields['fs']\n",
    "    sig = sig[:, 1]\n",
    "    length = len(sig)\n",
    "    \n",
    "    beat_loc = np.array(ann_ref.sample) # r-peak locations\n",
    "    ann_note = np.array(ann_ref.aux_note) # rhythm change flag\n",
    "    \n",
    "    return sig, length, fs, label, ann_note, beat_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(signal):\n",
    "\n",
    "    values = signal\n",
    "    values = values.reshape((len(values), 1))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(values)\n",
    "    normalized = scaler.transform(values)\n",
    "    normalized = [item for sublist in normalized for item in sublist]\n",
    "\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    return [lst[i:i + n] for i in range(0, len(lst), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chunked_input(seconds):\n",
    "        \n",
    "    ''' Builds chunked signal input  '''\n",
    "        \n",
    "    test_set = open(os.path.join(DATA_PATH, 'RECORDS'), 'r').read().splitlines()\n",
    "\n",
    "    input_df = pd.DataFrame(columns=[\"Sequence Number\", \"Chunked Signal\", \"Sequence Label\", \n",
    "                                     \"Chunked Label\", \"Signal Length\", \"AF Burden\"])\n",
    "      \n",
    "    for i, sample in enumerate(test_set):\n",
    "        \n",
    "        #print(\"\\n\\n\\n\", sample)\n",
    "        print(i, end='\\r')\n",
    "        sample_path = os.path.join(DATA_PATH, sample)\n",
    "        sig, sig_len, fs, label, label_arr, beat_loc = load_record(sample_path)\n",
    "        \n",
    "        r_peaks = beat_loc\n",
    "        chunksize = seconds*200\n",
    "        \n",
    "        sig = normalize(sig)\n",
    "        \n",
    "        ## Calculate exact AF ranges in sequence Label arr acts as an index \n",
    "        ## for which peaks in r_peaks are afib\n",
    "           \n",
    "        af_ranges = []\n",
    "        af_range = []\n",
    "                \n",
    "        for li, l in enumerate(label_arr):\n",
    "            if l == \"(AFIB\" or l == \"(AFL\":\n",
    "                printlabelarr = True\n",
    "                start = r_peaks[li] #r_peaks[min(len(r_peaks)-1, li)]\n",
    "                af_range.append(start)\n",
    "            if l == \"(N\":\n",
    "                stop = r_peaks[li] #r_peaks[min(len(r_peaks)-1, li)]\n",
    "                af_range.append(stop)\n",
    "                af_ranges.append(af_range)\n",
    "                af_range = []\n",
    "        \n",
    "        #print(\"\\n\", af_ranges)\n",
    "        \n",
    "        ## Label sections of signal as AF/non AF\n",
    "        loc_labels = [0]*sig_len\n",
    "        for rng in af_ranges:\n",
    "            start = rng[0]\n",
    "            stop = rng[1]\n",
    "            loc_labels[ start : stop ] = [1] * (stop-start) \n",
    "        \n",
    "        ## Break signal and label sequences down to n-second chunks\n",
    "        chunked_sig = chunks(sig, chunksize)[:-1]\n",
    "        chunked_label = chunks(loc_labels, chunksize)[:-1]\n",
    "        \n",
    "        ## Calculate AF Burden per sequence based on AF ranges\n",
    "        burden=0\n",
    "        for rng in af_ranges:\n",
    "            burden+=rng[1]-rng[0] \n",
    "        burden = burden/sig_len  \n",
    "\n",
    "        input_df.at[i, 'Sequence Number'] = i\n",
    "        input_df.at[i, 'Chunked Signal'] = chunked_sig\n",
    "        input_df.at[i, 'Chunked Label'] = chunked_label\n",
    "        input_df.at[i, 'Signal Length'] = sig_len\n",
    "        input_df.at[i, 'Sequence Label'] = label\n",
    "        input_df.at[i, 'AF Burden'] = burden\n",
    "        \n",
    "    ## Convert from sequence-level df into chunk-level df\n",
    "    input_df = input_df.explode([\"Chunked Signal\", \"Chunked Label\"])\n",
    "    input_df.dropna(subset=['Chunked Label'], inplace=True)\n",
    "\n",
    "    ## Assign most common granular label as overall chunk label\n",
    "    input_df[\"Chunked Label\"] = input_df[\"Chunked Label\"].apply(lambda x: Counter(x).most_common(1)[0][0])\n",
    "    \n",
    "    return input_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds=30\n",
    "chunk_df = build_chunked_input(seconds)\n",
    "chunk_df.dropna(inplace=True)\n",
    "chunk_df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "chunk_df = chunk_df.reset_index()\n",
    "chunk_df.to_feather(\"./chunk_df_1436_30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Embedding, MaxPooling1D\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "import visualkeras\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "chunk_df = pd.read_feather(\"./tempdata/chunk_df_1436_30\", columns=None, use_threads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split into train and test data (70-30 split). Ensure record chunks are not split between train and test\n",
    "\n",
    "cutoff = int(.7*max(chunk_df['Sequence Number']))\n",
    "train_df = chunk_df[chunk_df['Sequence Number'] < cutoff]\n",
    "test_df = chunk_df[chunk_df['Sequence Number'] >= cutoff]\n",
    "\n",
    "X_train = pd.DataFrame(train_df['Chunked Signal'].tolist())\n",
    "X_test = pd.DataFrame(test_df['Chunked Signal'].tolist())\n",
    "\n",
    "y_train = pd.DataFrame(train_df['Chunked Label'].tolist())\n",
    "y_test = pd.DataFrame(test_df['Chunked Label'].tolist())\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "batch = 16\n",
    "epochs = 3\n",
    "shape = np.size(X_train, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = (shape,1)))\n",
    "model.add(Conv1D(100, 10, activation='relu'))\n",
    "model.add(Conv1D(100, 10, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(160, 10, activation='relu'))\n",
    "model.add(Conv1D(160, 10, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer='rmsprop',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "X_train = np.expand_dims(X_train, 2)\n",
    "X_test = np.expand_dims(X_test, 2)\n",
    "\n",
    "model.fit(X_train,y_train, batch_size = batch, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    X_test_expand = np.expand_dims(X_test, 2)\n",
    "    score = model.evaluate(X_test_expand, y_test, batch_size = batch)\n",
    "except:\n",
    "    score = model.evaluate(X_test, y_test, batch_size = batch)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"full_model_1436_30.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"full_model_1436_30.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model \n",
    "\n",
    "# load json and create model\n",
    "json_file = open('full_model_1436_30.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"full_model_1436_30.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "#y_pred = model.predict(X_test, batch_size = batch)\n",
    "y_test['y_pred'] = y_pred[:,0] > threshold\n",
    "if \"index\" in y_test.columns: \n",
    "    y_test.drop(columns=['index'], inplace=True)\n",
    "y_test.columns=['y_true', 'y_pred']\n",
    "y_test['y_pred'] = y_test['y_pred'].astype(float)\n",
    "\n",
    "cm = confusion_matrix(y_test['y_true'], y_test['y_pred'])\n",
    "\n",
    "precision, recall, _, _ = precision_recall_fscore_support(y_test['y_true'], y_test['y_pred'], average='macro')\n",
    "\n",
    "print(\"\\n Accuracy: \", score[1])\n",
    "print(\"\\n Loss: \", score[0])\n",
    "print(\"\\n Precision: \", precision, \" Recall: \", recall)\n",
    "print(\"\\n F1 score: \", f1_score(y_test['y_true'], y_test['y_pred'], average='macro'))\n",
    "print(\"\\n Confusion Matrix: \\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append predictions to test dataset\n",
    "\n",
    "test_df.reset_index(inplace=True)\n",
    "y_test.reset_index(inplace=True)\n",
    "chunked_test = pd.concat([test_df, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Condense dataset back to the sequence level, calculate Predicted AF Burden\n",
    "\n",
    "chunked_test['y_pred_2'] = chunked_test['y_pred']\n",
    "\n",
    "seq_test = (chunked_test.drop(columns=['Chunked Signal'])\n",
    "      .groupby(['Sequence Number', 'Sequence Label', 'AF Burden', 'Signal Length'])\n",
    "      .agg({'Chunked Label': lambda x: x.tolist() , 'y_pred': lambda x: x.tolist(), 'y_pred_2':'sum', })\n",
    "      .rename({'y_pred_2' : 'AF Episodes'},axis=1)\n",
    "      .reset_index())\n",
    "\n",
    "seq_test['Predicted AF Burden'] = (seq_test['AF Episodes']*seconds*200) / seq_test['Signal Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate MAE for AF Burden Predications\n",
    "\n",
    "burden_mae = mean_absolute_error(seq_test['AF Burden'],seq_test['Predicted AF Burden'])\n",
    "burden_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize AF Burden\n",
    "\n",
    "plt.scatter(seq_test['AF Burden'], seq_test['Predicted AF Burden'])\n",
    "plt.xlabel(\"True Burden\")\n",
    "plt.ylabel(\"Predicted Burden\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
