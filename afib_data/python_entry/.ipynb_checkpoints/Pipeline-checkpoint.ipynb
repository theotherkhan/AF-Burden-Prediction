{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "This notebook runs a 1D CNN on ECG data from [The 4th China Physiological Signal Challenge 2021](https://physionet.org/content/cpsc2021/1.0.0/).\n",
    "\n",
    "The output of this notebook includes accuracy metrics on chunk-level classification of ECG Data, as well as AF Burden Predictions and MAE.\n",
    "\n",
    "To run this notebook, install the necessary requirements from the requirements.txt file, and download the data from the link above. Modify the DATA_PATH variable to poin to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import wfdb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/Hasan/Desktop/Workspace/cpsc2021-AFIB/afib_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_record(sample_path):\n",
    "    \n",
    "    '''  returns signal, global label, local labels ''' \n",
    "    \n",
    "    sig, fields = wfdb.rdsamp(sample_path)\n",
    "    ann_ref = wfdb.rdann(sample_path, 'atr')\n",
    "    \n",
    "    label = fields['comments'][0]\n",
    "    fs = fields['fs']\n",
    "    sig = sig[:, 1]\n",
    "    length = len(sig)\n",
    "    \n",
    "    #print(\"Signal: \", sig)\n",
    "    #print(\"\\nLabel: \", label)\n",
    "    #print(wfdb.rdsamp(sample_path))\n",
    "    #print(\"\\n\\n\", wfdb.rdann(sample_path, 'atr').aux_note)\n",
    "    \n",
    "    beat_loc = np.array(ann_ref.sample) # r-peak locations\n",
    "    ann_note = np.array(ann_ref.aux_note) # rhythm change flag\n",
    "    \n",
    "    return sig, length, fs, label, ann_note, beat_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(signal):\n",
    "\n",
    "    values = signal\n",
    "    values = values.reshape((len(values), 1))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(values)\n",
    "    normalized = scaler.transform(values)\n",
    "    normalized = [item for sublist in normalized for item in sublist]\n",
    "    #print(normalized)\n",
    "\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    return [lst[i:i + n] for i in range(0, len(lst), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chunked_input(seconds):\n",
    "        \n",
    "    ''' Builds chunked signal input  '''\n",
    "        \n",
    "    test_set = open(os.path.join(DATA_PATH, 'RECORDS'), 'r').read().splitlines()\n",
    "\n",
    "    input_df = pd.DataFrame(columns=[\"Sequence Number\", \"Chunked Signal\", \"Sequence Label\", \n",
    "                                     \"Chunked Label\", \"Signal Length\", \"AF Burden\"])\n",
    "      \n",
    "    for i, sample in enumerate(test_set):\n",
    "        \n",
    "        #print(\"\\n\\n\\n\", sample)\n",
    "        print(i, end='\\r')\n",
    "        sample_path = os.path.join(DATA_PATH, sample)\n",
    "        sig, sig_len, fs, label, label_arr, beat_loc = load_record(sample_path)\n",
    "        \n",
    "        r_peaks = beat_loc\n",
    "        #qrs_peaks = (qrs_detect(sig, fs)).astype(int)\n",
    "        #r_peaks = qrs_peaks\n",
    "        chunksize = seconds*200\n",
    "        \n",
    "        #print(sig)\n",
    "        #print(\"\\n\\nr_peaks: \", r_peaks, len(r_peaks))\n",
    "        #print(\"\\nqrs_detect: \", qrs_peaks, len(qrs_peaks))\n",
    "        \n",
    "        sig = normalize(sig)\n",
    "        \n",
    "        ## Calculate exact AF ranges in sequence Label arr acts as an index \n",
    "        ## for which peaks in r_peaks are afib\n",
    "           \n",
    "        af_ranges = []\n",
    "        af_range = []\n",
    "                \n",
    "        for li, l in enumerate(label_arr):\n",
    "            if l == \"(AFIB\" or l == \"(AFL\":\n",
    "                printlabelarr = True\n",
    "                start = r_peaks[li] #r_peaks[min(len(r_peaks)-1, li)]\n",
    "                af_range.append(start)\n",
    "            if l == \"(N\":\n",
    "                stop = r_peaks[li] #r_peaks[min(len(r_peaks)-1, li)]\n",
    "                af_range.append(stop)\n",
    "                af_ranges.append(af_range)\n",
    "                af_range = []\n",
    "        \n",
    "        #print(\"\\n\", af_ranges)\n",
    "        \n",
    "        ## Label sections of signal as AF/non AF\n",
    "        loc_labels = [0]*sig_len\n",
    "        for rng in af_ranges:\n",
    "            start = rng[0]\n",
    "            stop = rng[1]\n",
    "            loc_labels[ start : stop ] = [1] * (stop-start) \n",
    "        \n",
    "        ## Break signal and label sequences down to n-second chunks\n",
    "        chunked_sig = chunks(sig, chunksize)[:-1]\n",
    "        chunked_label = chunks(loc_labels, chunksize)[:-1]\n",
    "        \n",
    "        ## Calculate AF Burden per sequence based on AF ranges\n",
    "        burden=0\n",
    "        for rng in af_ranges:\n",
    "            burden+=rng[1]-rng[0] \n",
    "        burden = burden/sig_len  \n",
    "\n",
    "        input_df.at[i, 'Sequence Number'] = i\n",
    "        input_df.at[i, 'Chunked Signal'] = chunked_sig\n",
    "        input_df.at[i, 'Chunked Label'] = chunked_label\n",
    "        input_df.at[i, 'Signal Length'] = sig_len\n",
    "        input_df.at[i, 'Sequence Label'] = label\n",
    "        input_df.at[i, 'AF Burden'] = burden\n",
    "        \n",
    "    ## Convert from sequence-level df into chunk-level df\n",
    "    input_df = input_df.explode([\"Chunked Signal\", \"Chunked Label\"])\n",
    "    input_df.dropna(subset=['Chunked Label'], inplace=True)\n",
    "\n",
    "    ## Assign most common granular label as overall chunk label\n",
    "    input_df[\"Chunked Label\"] = input_df[\"Chunked Label\"].apply(lambda x: Counter(x).most_common(1)[0][0])\n",
    "    \n",
    "    return input_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds=10\n",
    "chunk_df = build_chunked_input(seconds)\n",
    "chunk_df.dropna(inplace=True)\n",
    "chunk_df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "chunk_df = chunk_df.reset_index()\n",
    "chunk_df.to_feather(\"./chunk_df_1436_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Embedding, MaxPooling1D\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.26 s, sys: 7.3 s, total: 10.6 s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chunk_df = pd.read_feather(\"./chunk_df_1436_10\", columns=None, use_threads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff:  996\n"
     ]
    }
   ],
   "source": [
    "## Split into train and test data (70-30 split). Ensure record chunks are not split between train and test\n",
    "\n",
    "cutoff = int(.7*max(chunk_df['Sequence Number']))\n",
    "print(\"Cutoff: \", cutoff)\n",
    "train_df = chunk_df[chunk_df['Sequence Number'] < cutoff]\n",
    "test_df = chunk_df[chunk_df['Sequence Number'] >= cutoff]\n",
    "\n",
    "X_train = pd.DataFrame(train_df['Chunked Signal'].tolist())\n",
    "X_test = pd.DataFrame(test_df['Chunked Signal'].tolist())\n",
    "\n",
    "y_train = pd.DataFrame(train_df['Chunked Label'].tolist())\n",
    "y_test = pd.DataFrame(test_df['Chunked Label'].tolist())\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-12 21:20:29.832760: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2000, 100)         200       \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1991, 100)         100100    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1982, 100)         100100    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 660, 100)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 651, 160)          160160    \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 642, 160)          256160    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 160)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 160)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 616,881\n",
      "Trainable params: 616,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "8490/8490 [==============================] - 2784s 328ms/step - loss: 0.2611 - accuracy: 0.8864\n",
      "Epoch 2/2\n",
      "8490/8490 [==============================] - 2842s 335ms/step - loss: 0.0732 - accuracy: 0.9765\n",
      "CPU times: user 9h 45min 7s, sys: 48min 28s, total: 10h 33min 35s\n",
      "Wall time: 1h 34min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8f2a40e80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch = 16\n",
    "epochs = 2\n",
    "shape = np.size(X_train, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = (shape,1)))\n",
    "model.add(Conv1D(100, 10, activation='relu'))\n",
    "model.add(Conv1D(100, 10, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(160, 10, activation='relu'))\n",
    "model.add(Conv1D(160, 10, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer='rmsprop',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "X_train = np.expand_dims(X_train, 2)\n",
    "#X_test = np.expand_dims(X_test, 2)\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train, batch_size = batch, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270/2270 [==============================] - 230s 101ms/step - loss: 0.4611 - accuracy: 0.9101\n",
      "CPU times: user 24min 7s, sys: 31.8 s, total: 24min 38s\n",
      "Wall time: 3min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.461062490940094, 0.9101123809814453]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "X_test = np.expand_dims(X_test, 2)\n",
    "score = model.evaluate(X_test, y_test, batch_size = batch)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "## Save Model & Weights\n",
    "\n",
    "try:\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"full_model_1400_10.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"full_model_1400_10.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "except:\n",
    "    print(\"Model failed to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy:  0.9101123809814453\n",
      "\n",
      " Loss:  0.461062490940094\n",
      "\n",
      " F1 score:  0.9100525955042035\n",
      "\n",
      " Confusion Matrix: \n",
      " [[16056  2020]\n",
      " [ 1244 16992]]\n",
      "CPU times: user 33min 51s, sys: 56.3 s, total: 34min 48s\n",
      "Wall time: 13min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size = batch)\n",
    "y_test['y_pred'] = y_pred[:,0] > threshold\n",
    "if \"index\" in y_test.columns: y_test.drop('index', inplace=True)\n",
    "y_test.columns=['y_true', 'y_pred']\n",
    "y_test['y_pred'] = y_test['y_pred'].astype(float)\n",
    "\n",
    "cm = confusion_matrix(y_test['y_true'], y_test['y_pred'])\n",
    "\n",
    "print(\"\\n Accuracy: \", score[1])\n",
    "print(\"\\n Loss: \", score[0])\n",
    "print(\"\\n F1 score: \", f1_score(y_test['y_true'], y_test['y_pred'], average='macro'))\n",
    "print(\"\\n Confusion Matrix: \\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append predictions to test dataset\n",
    "\n",
    "test_df.reset_index(inplace=True)\n",
    "y_test.reset_index(inplace=True)\n",
    "chunked_test = pd.concat([test_df, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Condense dataset back to the sequence level, calculate Predicted AF Burden\n",
    "\n",
    "chunked_test['y_pred_2'] = chunked_test['y_pred']\n",
    "\n",
    "seq_test = (chunked_test.drop(columns=['Chunked Signal'])\n",
    "      .groupby(['Sequence Number', 'Sequence Label', 'AF Burden', 'Signal Length'])\n",
    "      .agg({'Chunked Label': lambda x: x.tolist() , 'y_pred': lambda x: x.tolist(), 'y_pred_2':'sum', })\n",
    "      .rename({'y_pred_2' : 'AF Episodes'},axis=1)\n",
    "      .reset_index())\n",
    "\n",
    "seq_test['Predicted AF Burden'] = (seq_test['AF Episodes']*seconds*200) / seq_test['Signal Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12376731011513718"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculate MAE for AF Burden Predications\n",
    "\n",
    "burden_mae = mean_absolute_error(seq_test['AF Burden'],seq_test['Predicted AF Burden'])\n",
    "burden_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predicted Burden')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualize AF Burden\n",
    "\n",
    "plt.scatter(seq_test['AF Burden'], seq_test['Predicted AF Burden'])\n",
    "plt.xlabel(\"True Burden\")\n",
    "plt.ylabel(\"Predicted Burden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_test.to_pickle(\"final_test_10SEC.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
