{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import wfdb\n",
    "from utils import qrs_detect, comp_cosEn, save_dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_record(sample_path):\n",
    "    \n",
    "    '''  returns signal, global label, local labels ''' \n",
    "    \n",
    "    sig, fields = wfdb.rdsamp(sample_path)\n",
    "    ann_ref = wfdb.rdann(sample_path, 'atr')\n",
    "    \n",
    "    #print(wfdb.rdsamp(sample_path))\n",
    "    #print(\"\\n\\n\", wfdb.rdann(sample_path, 'atr').aux_note)\n",
    "    \n",
    "    label = fields['comments'][0]\n",
    "    fs = fields['fs']\n",
    "    sig = sig[:, 1]\n",
    "    length = len(sig)\n",
    "    \n",
    "    #print(\"Signal: \", sig)\n",
    "    #print(\"\\nLabel: \", label)\n",
    "    \n",
    "    beat_loc = np.array(ann_ref.sample) # r-peak locations\n",
    "    ann_note = np.array(ann_ref.aux_note) # rhythm change flag\n",
    "    \n",
    "    return sig, length, fs, label, ann_note, beat_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(signal):\n",
    "\n",
    "    values = signal\n",
    "    values = values.reshape((len(values), 1))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(values)\n",
    "    normalized = scaler.transform(values)\n",
    "    normalized = [item for sublist in normalized for item in sublist]\n",
    "    \n",
    "    #print(normalized)\n",
    "\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input():\n",
    "    \n",
    "    ''' Builds input DF '''\n",
    "\n",
    "    DATA_PATH = \"/Users/Hasan/Desktop/Workspace/cpsc2021-AFIB/afib_data\"\n",
    "    RESULT_PATH = \"/Users/Hasan/Desktop/Workspace/cpsc2021-AFIB/afib_data/output\"\n",
    "    if not os.path.exists(RESULT_PATH):\n",
    "        os.makedirs(RESULT_PATH)\n",
    "        \n",
    "    test_set = open(os.path.join(DATA_PATH, 'RECORDS'), 'r').read().splitlines()[0:10]\n",
    "    \n",
    "    input_df = pd.DataFrame(columns=[\"Signal\", \"Signal Length\", \"Label\"])\n",
    "  \n",
    "    for i, sample in enumerate(test_set):\n",
    "        \n",
    "        #print(\"\\n\\n\\n\", sample)\n",
    "        sample_path = os.path.join(DATA_PATH, sample)\n",
    "        sig, sig_len, fs, label, label_arr, beat_loc  = load_record(sample_path)\n",
    "        \n",
    "        #sig = normalize_signal(sig)\n",
    "        \n",
    "        input_df.at[i, 'Signal'] = sig\n",
    "        input_df.at[i, 'Signal Length'] = sig_len\n",
    "        input_df.at[i, 'Label'] = label\n",
    "    \n",
    "        #input_df.append(build_seq_input(sample_path))\n",
    "        #pred_dict = challenge_entry(sample_path)\n",
    "        \n",
    "    return input_df\n",
    "    \n",
    "df = build_input()\n",
    "df.to_pickle(\"/Users/Hasan/Desktop/Workspace/cpsc2021-AFIB/afib_data/df.pkl\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    return [lst[i:i + n] for i in range(0, len(lst), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31783, 7)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31779 entries, 0 to 599\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Sequence Number  31779 non-null  object \n",
      " 1   Sequence Name    31779 non-null  object \n",
      " 2   Signal           31779 non-null  object \n",
      " 3   Sequence Label   31779 non-null  object \n",
      " 4   Chunk Label      31779 non-null  float64\n",
      " 5   Signal Length    31779 non-null  object \n",
      " 6   AF Burden        31779 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "def build_chunked_input(start, stop):\n",
    "        \n",
    "    ''' Builds chunked DF input  '''\n",
    "\n",
    "    DATA_PATH = \"/Users/Hasan/Desktop/Workspace/cpsc2021-AFIB/afib_data\"\n",
    "    RESULT_PATH = \"/Users/Hasan/Desktop/Workspace/cpsc2021-AFIB/afib_data/output\"\n",
    "    if not os.path.exists(RESULT_PATH):\n",
    "        os.makedirs(RESULT_PATH)\n",
    "        \n",
    "    test_set = open(os.path.join(DATA_PATH, 'RECORDS'), 'r').read().splitlines()[start:stop]\n",
    "    seconds = 30\n",
    "    chunksize = seconds*200\n",
    "    \n",
    "    input_df = pd.DataFrame(columns=[\"Sequence Number\", \"Sequence Name\", \"Signal\", \"Granular Labels\", \"Sequence Label\", \"Chunk Label\", \"Signal Length\", \"AF Burden\"])\n",
    "  \n",
    "    #test_set=[\"Training_set_II/data_86_9\"]\n",
    "    \n",
    "    for i, sample in enumerate(test_set):\n",
    "        \n",
    "        #print(\"\\n\\n\\n\", sample)\n",
    "        #print(i, end='\\r')\n",
    "        sample_path = os.path.join(DATA_PATH, sample)\n",
    "        sig, sig_len, fs, label, label_arr, beat_loc = load_record(sample_path)\n",
    "        loc_labels = [0]*sig_len\n",
    "        r_peaks = beat_loc #qrs_detect(sig, fs)\n",
    "        \n",
    "        #print(sig)\n",
    "        sig = normalize(sig)\n",
    "        \n",
    "        printlabelarr = False \n",
    "        af_ranges = []\n",
    "        af_range = []\n",
    "        \n",
    "        ## Calculate exact AF ranges in sequence\n",
    "        ''' Label arr acts as an index for which peaks in r_peaks are afib; '''\n",
    "        \n",
    "        #print('Label arr: ', label_arr)\n",
    "        #print(\"\\nQRS Peak locations: \", r_peaks)\n",
    "        \n",
    "        for li, l in enumerate(label_arr):\n",
    "            if l == \"(AFIB\" or l == \"(AFL\":\n",
    "                #print(\"AFIB detected\")\n",
    "                printlabelarr = True\n",
    "                start = r_peaks[li]\n",
    "                af_range.append(start)\n",
    "                #print(np.where(label_arr == l)[0])\n",
    "                #loc_labels[ r_peaks[ label_arr.index(mini_label) ]] = 'AFIB'\n",
    "            if l == \"(N\":\n",
    "                stop = r_peaks[li]\n",
    "                af_range.append(stop)\n",
    "                af_ranges.append(af_range)\n",
    "                af_range = []\n",
    "        \n",
    "        #print(\"\\n\", af_ranges)\n",
    "        ## Label AF for AF sections of the signal\n",
    "        for rng in af_ranges:\n",
    "            start = rng[0]\n",
    "            stop = rng[1]\n",
    "            #print(\"Signal AF start/stop ranges: \", start, stop)\n",
    "            #print(r_peaks[start], r_peaks[stop])\n",
    "            loc_labels[ start : stop ] = [1] * (stop-start) \n",
    "        \n",
    "       \n",
    "        #print(\"Signal: \", sig)\n",
    "        #print(\"Signal len: \", sig_len)\n",
    "        \n",
    "        #print(len(r_peaks))\n",
    "        \n",
    "        \n",
    "        #if printlabelarr: \n",
    "            #print(\"Label Arr: \", label_arr)\n",
    "            #print(len(label_arr))\n",
    "            #print(\"AF ranges: \", af_ranges)\n",
    "            #print(\"Granular Labels: \", loc_labels[0:10])\n",
    "            #print(len(loc_labels))\n",
    "        #print(\"Sequence Label: \", label)\n",
    "       \n",
    "        #chunked_sig   = np.array_split(sig, chunksize)\n",
    "        #chunked_label = np.array_split(loc_labels, chunksize)\n",
    "        \n",
    "        chunked_sig = chunks(sig, chunksize)[:-1]\n",
    "        chunked_label = chunks(loc_labels, chunksize)[:-1]\n",
    "        \n",
    "        burden=0\n",
    "        for rng in af_ranges:\n",
    "            burden+=rng[1]-rng[0] \n",
    "        burden = burden/sig_len\n",
    "            \n",
    "        #print('Burden: ', burden)\n",
    "\n",
    "        input_df.at[i, 'Sequence Number'] = i\n",
    "        input_df.at[i, 'Sequence Name'] = sample\n",
    "        input_df.at[i, 'Signal'] = chunked_sig\n",
    "        input_df.at[i, 'Granular Labels'] = chunked_label\n",
    "        input_df.at[i, 'Signal Length'] = sig_len\n",
    "        input_df.at[i, 'Sequence Label'] = label\n",
    "        input_df.at[i, 'AF Burden'] = burden\n",
    "        \n",
    "    \n",
    "        #input_df.append(build_seq_input(sample_path))\n",
    "        #pred_dict = challenge_entry(sample_path)\n",
    "        \n",
    "    input_df = input_df.explode([\"Signal\", \"Granular Labels\"])\n",
    "    \n",
    "    #print(\"\\n\", input_df[\"Granular Labels\"])\n",
    "    \n",
    "    #input_df[\"Chunk Label\"] = input_df[\"Granular Labels\"].apply(lambda x: Counter(x).most_common(1)[0][0])\n",
    "    #input_df[\"Chunk Label\"] = input_df[\"Granular Labels\"].apply(lambda x: Counter(x).most_common(1)[0][0])\n",
    "    input_df[\"Chunk Label\"] = input_df[\"Granular Labels\"].str[0]\n",
    "     \n",
    "    input_df = input_df.drop(['Granular Labels'], axis=1)\n",
    "        \n",
    "    return input_df\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for i in range(0,1):\n",
    "    df = build_chunked_input(0+(600*i), 600+(600*i))\n",
    "    print(df.shape)\n",
    "    dfs.append(df)   \n",
    "    \n",
    "chunk_df = pd.concat(dfs)\n",
    "chunk_df.dropna(inplace=True)\n",
    "chunk_df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df.to_pickle(\"/Users/Hasan/Desktop/Workspace/cpsc2021-AFIB/afib_data/chunk_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    23996\n",
       "1.0     7783\n",
       "Name: Chunk Label, dtype: int64"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_df['Chunk Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Embedding, MaxPooling1D\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8445, 6000), (3620, 6000), (8445, 1), (3620, 1))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.DataFrame(chunk_df['Signal'].tolist())\n",
    "y = pd.DataFrame(chunk_df['Chunk Label'].tolist())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence Number</th>\n",
       "      <th>Sequence Name</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Sequence Label</th>\n",
       "      <th>Chunk Label</th>\n",
       "      <th>Signal Length</th>\n",
       "      <th>AF Burden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599</td>\n",
       "      <td>Training_set_I/data_41_11</td>\n",
       "      <td>[0.4543817618604368, 0.45355774953077077, 0.45...</td>\n",
       "      <td>non atrial fibrillation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>586960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599</td>\n",
       "      <td>Training_set_I/data_41_11</td>\n",
       "      <td>[0.1168876749118764, 0.10947156394488272, 0.10...</td>\n",
       "      <td>non atrial fibrillation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>586960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599</td>\n",
       "      <td>Training_set_I/data_41_11</td>\n",
       "      <td>[0.45461065417423285, 0.46408679596539154, 0.4...</td>\n",
       "      <td>non atrial fibrillation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>586960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599</td>\n",
       "      <td>Training_set_I/data_41_11</td>\n",
       "      <td>[0.5242549555185937, 0.5244075503944579, 0.524...</td>\n",
       "      <td>non atrial fibrillation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>586960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599</td>\n",
       "      <td>Training_set_I/data_41_11</td>\n",
       "      <td>[0.4555262234294173, 0.4564875711473609, 0.426...</td>\n",
       "      <td>non atrial fibrillation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>586960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sequence Number              Sequence Name  \\\n",
       "599             599  Training_set_I/data_41_11   \n",
       "599             599  Training_set_I/data_41_11   \n",
       "599             599  Training_set_I/data_41_11   \n",
       "599             599  Training_set_I/data_41_11   \n",
       "599             599  Training_set_I/data_41_11   \n",
       "\n",
       "                                                Signal  \\\n",
       "599  [0.4543817618604368, 0.45355774953077077, 0.45...   \n",
       "599  [0.1168876749118764, 0.10947156394488272, 0.10...   \n",
       "599  [0.45461065417423285, 0.46408679596539154, 0.4...   \n",
       "599  [0.5242549555185937, 0.5244075503944579, 0.524...   \n",
       "599  [0.4555262234294173, 0.4564875711473609, 0.426...   \n",
       "\n",
       "              Sequence Label  Chunk Label Signal Length AF Burden  \n",
       "599  non atrial fibrillation          0.0        586960       0.0  \n",
       "599  non atrial fibrillation          0.0        586960       0.0  \n",
       "599  non atrial fibrillation          0.0        586960       0.0  \n",
       "599  non atrial fibrillation          0.0        586960       0.0  \n",
       "599  non atrial fibrillation          0.0        586960       0.0  "
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df.sort_values(by=['Sequence Number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = chunk_df[chunk_df['Sequence Number'] < 400]\n",
    "test_df = chunk_df[chunk_df['Sequence Number'] >= 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jb/m0v9kc5d51xct83pk_v1ghcr0000gn/T/ipykernel_1335/341698209.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#test_df = chunk_df.sample(frac = 0.3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Signal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Signal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cpsc/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    692\u001b[0m                         \u001b[0;31m# ndarray], Index, Series], Sequence[Any]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[0m\u001b[1;32m    695\u001b[0m                         \u001b[0;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                         \u001b[0;31m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cpsc/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cpsc/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m     \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_finalize_columns_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cpsc/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cpsc/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[0;34m(content, dtype)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cpsc/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cpsc/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"O\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train_df = chunk_df.sample(frac = 0.7)\n",
    "#test_df = chunk_df.sample(frac = 0.3)\n",
    "\n",
    "X_train = pd.DataFrame(train_df['Signal'].tolist())\n",
    "X_test = pd.DataFrame(test_df['Signal'].tolist())\n",
    "\n",
    "y_train = pd.DataFrame(train_df['Chunk Label'].tolist())\n",
    "y_test = pd.DataFrame(test_df['Chunk Label'].tolist())\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 6000, 100)         200       \n",
      "                                                                 \n",
      " conv1d_36 (Conv1D)          (None, 5991, 100)         100100    \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 5982, 100)         100100    \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 1994, 100)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_38 (Conv1D)          (None, 1985, 160)         160160    \n",
      "                                                                 \n",
      " conv1d_39 (Conv1D)          (None, 1976, 160)         256160    \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 160)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 160)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 616,881\n",
      "Trainable params: 616,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1987/1987 [==============================] - 2423s 1s/step - loss: 0.4900 - accuracy: 0.7790\n",
      "\r"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jb/m0v9kc5d51xct83pk_v1ghcr0000gn/T/ipykernel_1335/292968852.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cpsc/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cpsc/lib/python3.8/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0mnumdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m         \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'%'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumdigits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd/%d ['\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    }
   ],
   "source": [
    "batch = 16\n",
    "epochs = 1\n",
    "shape = np.size(X_train, 1)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = (shape,1)))\n",
    "model.add(Conv1D(100, 10, activation='relu'))\n",
    "model.add(Conv1D(100, 10, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(160, 10, activation='relu'))\n",
    "model.add(Conv1D(160, 10, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer='rmsprop',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "X_train = np.expand_dims(X_train, 2)\n",
    "X_test = np.expand_dims(X_test, 2)\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train, batch_size = batch, epochs = epochs)\n",
    "score = model.evaluate(X_test, y_test, batch_size = batch)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jb/m0v9kc5d51xct83pk_v1ghcr0000gn/T/ipykernel_1335/2470954125.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cpsc/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cpsc/lib/python3.8/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0mnumdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m         \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'%'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumdigits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd/%d ['\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size = batch)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 0, 1), dtype=float64)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy:  0.7046818733215332\n",
      "\n",
      " Loss:  0.6038762927055359\n",
      "\n",
      " F1 score:  0.613558219299176\n",
      "\n",
      " Confusion Matrix: \n",
      " [[1983  135]\n",
      " [ 849  365]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size = batch)\n",
    "y_test['y_pred'] = y_pred[:,0] > threshold\n",
    "if \"index\" in y_test.columns: y_test.drop('index', inplace=True)\n",
    "y_test.columns=['y_true', 'y_pred']\n",
    "y_test['y_pred'] = y_test['y_pred'].astype(float)\n",
    "\n",
    "cm = confusion_matrix(y_test['y_true'], y_test['y_pred'])\n",
    "\n",
    "print(\"\\n Accuracy: \", score[1])\n",
    "print(\"\\n Loss: \", score[0])\n",
    "print(\"\\n F1 score: \", f1_score(y_test['y_true'], y_test['y_pred'], average='macro'))\n",
    "print(\"\\n Confusion Matrix: \\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.reset_index(inplace=True)\n",
    "y_test.reset_index(inplace=True)\n",
    "\n",
    "final = pd.concat([test_df, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence Number</th>\n",
       "      <th>Sequence Name</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Sequence Label</th>\n",
       "      <th>Chunk Label</th>\n",
       "      <th>Signal Length</th>\n",
       "      <th>AF Burden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training_set_I/data_31_1</td>\n",
       "      <td>[0.2241466131567302, 0.20606412036683808, 0.20...</td>\n",
       "      <td>paroxysmal atrial fibrillation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30483</td>\n",
       "      <td>0.142079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training_set_I/data_31_1</td>\n",
       "      <td>[0.2067202783330536, 0.214350022126257, 0.2071...</td>\n",
       "      <td>paroxysmal atrial fibrillation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30483</td>\n",
       "      <td>0.142079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training_set_I/data_31_1</td>\n",
       "      <td>[0.2526513359681382, 0.2470968824866861, 0.233...</td>\n",
       "      <td>paroxysmal atrial fibrillation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30483</td>\n",
       "      <td>0.142079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training_set_I/data_31_1</td>\n",
       "      <td>[0.2170051729662918, 0.21953824790563534, 0.21...</td>\n",
       "      <td>paroxysmal atrial fibrillation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30483</td>\n",
       "      <td>0.142079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training_set_I/data_31_1</td>\n",
       "      <td>[0.4459127462499809, 0.4473318785955167, 0.454...</td>\n",
       "      <td>paroxysmal atrial fibrillation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30483</td>\n",
       "      <td>0.142079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sequence Number             Sequence Name  \\\n",
       "2               2  Training_set_I/data_31_1   \n",
       "2               2  Training_set_I/data_31_1   \n",
       "2               2  Training_set_I/data_31_1   \n",
       "2               2  Training_set_I/data_31_1   \n",
       "2               2  Training_set_I/data_31_1   \n",
       "\n",
       "                                              Signal  \\\n",
       "2  [0.2241466131567302, 0.20606412036683808, 0.20...   \n",
       "2  [0.2067202783330536, 0.214350022126257, 0.2071...   \n",
       "2  [0.2526513359681382, 0.2470968824866861, 0.233...   \n",
       "2  [0.2170051729662918, 0.21953824790563534, 0.21...   \n",
       "2  [0.4459127462499809, 0.4473318785955167, 0.454...   \n",
       "\n",
       "                   Sequence Label  Chunk Label Signal Length AF Burden  \n",
       "2  paroxysmal atrial fibrillation          0.0         30483  0.142079  \n",
       "2  paroxysmal atrial fibrillation          0.0         30483  0.142079  \n",
       "2  paroxysmal atrial fibrillation          0.0         30483  0.142079  \n",
       "2  paroxysmal atrial fibrillation          0.0         30483  0.142079  \n",
       "2  paroxysmal atrial fibrillation          0.0         30483  0.142079  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"Sequence Number\"]==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sequence Number</th>\n",
       "      <th>Sequence Name</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Sequence Label</th>\n",
       "      <th>Chunk Label</th>\n",
       "      <th>Signal Length</th>\n",
       "      <th>AF Burden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, Sequence Number, Sequence Name, Signal, Sequence Label, Chunk Label, Signal Length, AF Burden]\n",
       "Index: []"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df[\"Sequence Number\"]==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sequence Number</th>\n",
       "      <th>Sequence Name</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Sequence Label</th>\n",
       "      <th>Chunk Label</th>\n",
       "      <th>Signal Length</th>\n",
       "      <th>AF Burden</th>\n",
       "      <th>index</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_pred_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>Training_set_I/data_24_25</td>\n",
       "      <td>[0.5300840797766009, 0.5392092533532726, 0.548...</td>\n",
       "      <td>persistent atrial fibrillation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21969</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>Training_set_I/data_24_25</td>\n",
       "      <td>[0.4437764179878836, 0.4480338150244916, 0.463...</td>\n",
       "      <td>persistent atrial fibrillation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21969</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>Training_set_I/data_24_25</td>\n",
       "      <td>[0.49362916393267486, 0.5075915950742376, 0.50...</td>\n",
       "      <td>persistent atrial fibrillation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21969</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>Training_set_I/data_53_6</td>\n",
       "      <td>[0.2733737201104787, 0.31974730288556913, 0.32...</td>\n",
       "      <td>non atrial fibrillation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>Training_set_I/data_53_6</td>\n",
       "      <td>[0.28548975325408577, 0.2827125265133597, 0.24...</td>\n",
       "      <td>non atrial fibrillation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Sequence Number              Sequence Name  \\\n",
       "0    150             150  Training_set_I/data_24_25   \n",
       "1    150             150  Training_set_I/data_24_25   \n",
       "2    150             150  Training_set_I/data_24_25   \n",
       "3    151             151   Training_set_I/data_53_6   \n",
       "4    151             151   Training_set_I/data_53_6   \n",
       "\n",
       "                                              Signal  \\\n",
       "0  [0.5300840797766009, 0.5392092533532726, 0.548...   \n",
       "1  [0.4437764179878836, 0.4480338150244916, 0.463...   \n",
       "2  [0.49362916393267486, 0.5075915950742376, 0.50...   \n",
       "3  [0.2733737201104787, 0.31974730288556913, 0.32...   \n",
       "4  [0.28548975325408577, 0.2827125265133597, 0.24...   \n",
       "\n",
       "                   Sequence Label  Chunk Label Signal Length AF Burden  index  \\\n",
       "0  persistent atrial fibrillation          1.0         21969  0.999954      0   \n",
       "1  persistent atrial fibrillation          1.0         21969  0.999954      1   \n",
       "2  persistent atrial fibrillation          1.0         21969  0.999954      2   \n",
       "3         non atrial fibrillation          0.0         53095       0.0      3   \n",
       "4         non atrial fibrillation          0.0         53095       0.0      4   \n",
       "\n",
       "   y_true  y_pred  y_pred_2  \n",
       "0     1.0     0.0       0.0  \n",
       "1     1.0     0.0       0.0  \n",
       "2     1.0     0.0       0.0  \n",
       "3     0.0     0.0       0.0  \n",
       "4     0.0     0.0       0.0  "
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['y_pred_2'] = final['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "final2 = (final.drop(columns=['Signal'])\n",
    "      .groupby(['Sequence Number', 'Sequence Label', 'AF Burden', 'Signal Length'])\n",
    "      .agg({'Chunk Label': lambda x: x.tolist() , 'y_pred': lambda x: x.tolist(), 'y_pred_2':'sum', })\n",
    "      .rename({'y_pred_2' : 'AF Episodes'},axis=1)\n",
    "      .reset_index())\n",
    "final2['Predicted AF Burden'] = (final2['AF Episodes']*30*200) / final2['Signal Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence Number</th>\n",
       "      <th>Sequence Label</th>\n",
       "      <th>AF Burden</th>\n",
       "      <th>Signal Length</th>\n",
       "      <th>Chunk Label</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>AF Episodes</th>\n",
       "      <th>Predicted AF Burden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>159</td>\n",
       "      <td>persistent atrial fibrillation</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4742450</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>365.0</td>\n",
       "      <td>0.461787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>175</td>\n",
       "      <td>non atrial fibrillation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>401824</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.671936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>178</td>\n",
       "      <td>non atrial fibrillation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>414798</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.911287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>187</td>\n",
       "      <td>non atrial fibrillation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>869143</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.041420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>194</td>\n",
       "      <td>non atrial fibrillation</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>420518</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.285362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>197</td>\n",
       "      <td>paroxysmal atrial fibrillation</td>\n",
       "      <td>0.052267</td>\n",
       "      <td>99183</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sequence Number                  Sequence Label  AF Burden  Signal Length  \\\n",
       "9               159  persistent atrial fibrillation   1.000000        4742450   \n",
       "25              175         non atrial fibrillation   0.000000         401824   \n",
       "28              178         non atrial fibrillation   0.000000         414798   \n",
       "37              187         non atrial fibrillation   0.000000         869143   \n",
       "44              194         non atrial fibrillation   0.000000         420518   \n",
       "47              197  paroxysmal atrial fibrillation   0.052267          99183   \n",
       "\n",
       "                                          Chunk Label  \\\n",
       "9   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "25  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "28  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "37  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "44  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "47  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                               y_pred  AF Episodes  \\\n",
       "9   [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...        365.0   \n",
       "25  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         45.0   \n",
       "28  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...         63.0   \n",
       "37  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          6.0   \n",
       "44  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         20.0   \n",
       "47  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          1.0   \n",
       "\n",
       "    Predicted AF Burden  \n",
       "9              0.461787  \n",
       "25             0.671936  \n",
       "28             0.911287  \n",
       "37             0.041420  \n",
       "44             0.285362  \n",
       "47             0.060494  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final2[final2['AF Episodes']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2190000"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "365*30*200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
